{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Импорты**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во признаков: 4\n",
      "(135, 4) (135,)\n",
      "Точность: 100.00%\n",
      "Accuracy: 100.00%\n",
      "Кол-во признаков: 4\n",
      "Количество кластеров: 3\n",
      "Кластер 1: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "Кластер 2: [118, 50, 51, 52, 100, 102, 104, 105, 107, 108, 109, 112, 116, 117, 120, 122, 124, 125, 128, 129, 130, 131, 132, 135, 136, 139, 140, 141, 143, 144, 145]\n",
      "Кластер 3: [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 101, 103, 106, 110, 111, 113, 114, 115, 119, 121, 123, 126, 127, 133, 134, 137, 138, 142, 146, 147, 148, 149]\n",
      "Метки:\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 1 2 1 1 2 1 1 1 2\n",
      " 2 1 2 2 2 1 1 1 2 1 2 1 2 1 1 2 2 1 1 1 1 1 2 2 1 1 2 2 1 1 1 2 1 1 1 2 2\n",
      " 2 2]\n",
      "Кол-во признаков: 4\n",
      "Центры кластеров:\n",
      "[[6.85       3.07368421 5.74210526 2.07105263]\n",
      " [5.006      3.428      1.462      0.246     ]\n",
      " [5.9016129  2.7483871  4.39354839 1.43387097]]\n",
      "Метки кластеров:\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 0 0 0 0 2 0 0 0 0\n",
      " 0 0 2 2 0 0 0 0 2 0 2 0 2 0 0 2 2 0 0 0 0 0 2 0 0 0 0 2 0 0 0 2 0 0 0 2 0\n",
      " 0 2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "%run lab4.ipynb\n",
    "%run lab5.ipynb\n",
    "%run lab2.ipynb\n",
    "%run lab3.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Оценка классификаторов**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def accuracy(y_pred, y_true):\n",
    "    return np.mean(y_pred == y_true)\n",
    "\n",
    "def precision(y_pred, y_true):\n",
    "    t_p = np.sum((y_pred == 1) & (y_true == 1))\n",
    "    f_p = np.sum((y_true == -1) & (y_pred == 1))\n",
    "    return t_p / (t_p + f_p) if (t_p + f_p) > 0 else 0\n",
    "\n",
    "def recall(y_pred, y_true):\n",
    "    t_p = np.sum((y_pred == 1) & (y_true == 1))\n",
    "    f_n = np.sum((y_pred == -1) & (y_true == 1))\n",
    "    return t_p / (t_p + f_n) if (t_p + f_n) > 0 else 0\n",
    "\n",
    "def f1(y_pred, y_true):\n",
    "    pre = precision(y_pred, y_true)\n",
    "    re = recall(y_pred, y_true)\n",
    "    return 2 * (pre * re) / (pre + re) if (pre + re) > 0 else 0\n",
    "\n",
    "\n",
    "def mse(y_pred, y_true):\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "def r_squared(y_pred, y_true):\n",
    "    return 1 - (mse(y_pred, y_true) / mse(np.mean(y_true), y_true))\n",
    "\n",
    "def confusion_matrix(y_pred, y_true):\n",
    "    unique_labels = np.unique(y_true)\n",
    "    matrix = pd.DataFrame(data=np.zeros((len(unique_labels), len(unique_labels)), dtype=int), columns = np.unique(y_true), index = np.unique(y_true))\n",
    "    #matrix = np.zeros((len(unique_labels), len(unique_labels)), dtype=int)\n",
    "    for y_t, y_p in zip(y_true, y_pred):\n",
    "        matrix.loc[y_t, y_p] += 1\n",
    "    \n",
    "    return matrix\n",
    "\n",
    "def classifiaction_metrics(y_pred, y_true, twoClasses=True):\n",
    "    s = []\n",
    "    metrics = [accuracy, precision, recall, f1, mse, r_squared, confusion_matrix] if twoClasses else [accuracy, mse, r_squared, confusion_matrix]\n",
    "    for metric in metrics:\n",
    "        s.append(metric(y_pred, y_true))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc          1.0\n",
      "pre          1.0\n",
      "re           1.0\n",
      "f1           1.0\n",
      "mse          0.0\n",
      "r squared    1.0\n",
      "Name: mean, dtype: float64\n",
      "    -1   1\n",
      "-1  14   0\n",
      " 1   0  16\n",
      "    -1   1\n",
      "-1  14   0\n",
      " 1   0  16\n",
      "    -1   1\n",
      "-1  14   0\n",
      " 1   0  16\n",
      "    -1   1\n",
      "-1  15   0\n",
      " 1   0  15\n",
      "    -1   1\n",
      "-1  16   0\n",
      " 1   0  14\n",
      "    -1   1\n",
      "-1  13   0\n",
      " 1   0  17\n",
      "    -1   1\n",
      "-1  16   0\n",
      " 1   0  14\n",
      "    -1   1\n",
      "-1  15   0\n",
      " 1   0  15\n",
      "    -1   1\n",
      "-1  18   0\n",
      " 1   0  12\n",
      "    -1   1\n",
      "-1  14   0\n",
      " 1   0  16\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X = X[y != 2]\n",
    "y = y[y != 2]\n",
    "y = np.where(y == 0, -1, 1)\n",
    "\n",
    "metrics = []\n",
    "for _ in range(10): # кросс-валидация\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "    svm = SVM(learning_rate=0.1, lambda_param=0.1, n_iters=100)\n",
    "    svm.fit(X_train, y_train)\n",
    "    y_pred = svm.predict(X_test)\n",
    "    metrics.append(classifiaction_metrics(y_pred, y_test))\n",
    "\n",
    "df = pd.DataFrame(data=metrics, columns=['acc', 'pre', 're', 'f1', 'mse', 'r squared', 'con'])\n",
    "\n",
    "\n",
    "print(df.describe().loc['mean'])\n",
    "for sample in metrics:\n",
    "    print(sample[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc          0.96000\n",
      "mse          0.04000\n",
      "r squared    0.94046\n",
      "Name: mean, dtype: float64\n",
      "confusion matrixes:\n",
      "   0  1  2\n",
      "0  6  0  0\n",
      "1  0  3  1\n",
      "2  0  0  5\n",
      "   0  1  2\n",
      "0  7  0  0\n",
      "1  0  5  0\n",
      "2  0  0  3\n",
      "   0  1  2\n",
      "0  6  0  0\n",
      "1  0  6  0\n",
      "2  0  0  3\n",
      "   0  1  2\n",
      "0  7  0  0\n",
      "1  0  2  0\n",
      "2  0  1  5\n",
      "   0  1  2\n",
      "0  7  0  0\n",
      "1  0  5  0\n",
      "2  0  0  3\n",
      "   0  1  2\n",
      "0  3  0  0\n",
      "1  0  5  0\n",
      "2  0  0  7\n",
      "   0  1  2\n",
      "0  5  0  0\n",
      "1  0  5  1\n",
      "2  0  0  4\n",
      "   0  1  2\n",
      "0  5  0  0\n",
      "1  0  4  1\n",
      "2  0  0  5\n",
      "   0  1  2\n",
      "0  4  0  0\n",
      "1  0  5  1\n",
      "2  0  0  5\n",
      "   0  1  2\n",
      "0  6  0  0\n",
      "1  0  4  1\n",
      "2  0  0  4\n"
     ]
    }
   ],
   "source": [
    "metrics = []\n",
    "for _ in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "    y_pred = np.array([knn(X_train, y_train, x_test, 5) for x_test in X_test])\n",
    "    metrics.append(classifiaction_metrics(y_pred, y_test, twoClasses=False))\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data=metrics, columns=['acc', 'mse', 'r squared', 'con'])\n",
    "\n",
    "\n",
    "print(df.describe().loc['mean'])\n",
    "print('confusion matrixes:')\n",
    "for sample in metrics:\n",
    "    print(sample[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Оценка кластеризации**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def silhouette(X, centers, labels):\n",
    "    score = []\n",
    "    for i, x_test in enumerate(X):\n",
    "        a = np.mean([euclidean_distance(x_test, x_same) for j, x_same in enumerate(X) if labels[i] == labels[j] and j != i])\n",
    "        d = [euclidean_distance(x_test, x_other) for j, x_other in enumerate(X)]\n",
    "        min = float('inf')\n",
    "        k = 0\n",
    "        for z, x in enumerate(d):\n",
    "            if labels[z] == labels[i]:\n",
    "                continue\n",
    "            if x < min:\n",
    "                min = x\n",
    "                k = z\n",
    "        b = np.mean([dis for i, dis in enumerate(d) if labels[k] == labels[i]])\n",
    "        score.append((b - a) / max(a, b) if max(a, b) > 0 else 0)\n",
    "    return np.mean(score)\n",
    "\n",
    "def di(X, centers, labels):\n",
    "    other_min = np.min([euclidean_distance(x_test, x_other) for j, x_other in enumerate(X)\n",
    "                        for i, x_test in enumerate(X) if labels[i] != labels[j]])\n",
    "    same_max = np.max([euclidean_distance(x_test, x_same) for j, x_same in enumerate(X)\n",
    "                       for i, x_test in enumerate(X) if labels[i] == labels[j] and j != i])\n",
    "    return other_min / same_max\n",
    "    \n",
    "def dbi(X, centers, labels):\n",
    "    c = []\n",
    "    for i in range(len(centers)):\n",
    "        same_dis = np.sum([euclidean_distance(centers[i], x)\n",
    "                           for j, x in enumerate(X) if labels[j] == i]) / np.linalg.norm(centers[i])\n",
    "        other_dis = []\n",
    "        between_dis = []\n",
    "        for j in range(len(centers)):\n",
    "            if j != i:\n",
    "                other_dis.append(np.sum([euclidean_distance(centers[j], x)\n",
    "                                         for z, x in enumerate(X) if labels[z] == j]) / np.linalg.norm(centers[j]) + same_dis)\n",
    "                between_dis.append(euclidean_distance(centers[i], centers[j]))\n",
    "        c.append(np.max(other_dis) / np.min(between_dis))\n",
    "    \n",
    "    return np.mean(c)\n",
    "\n",
    "def dbcv(X, centers, labels):\n",
    "    c = []\n",
    "    for i, ix in enumerate(X):\n",
    "        max_d_other = np.max([euclidean_distance(ix, jx) for j, jx in enumerate(X) if labels[i] != labels[j]])\n",
    "        for j, jx in enumerate(X):\n",
    "            if i != j:\n",
    "                c.append(euclidean_distance(ix, jx) / max_d_other)\n",
    "\n",
    "    return np.mean(c)\n",
    "\n",
    "def cluster_metrics(X, labels, centers):\n",
    "    return [ m(X, centers, labels) for m in [silhouette, di, dbi, dbcv]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Максимин и k-средних"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxmin\n",
      "   acc  mse  r squared       sil        di       dbi      dbcv\n",
      "0  0.5  0.5       0.25  0.522804  0.046575  4.458009  0.479025\n",
      "confusion matrixes:\n",
      "    0   1   2\n",
      "0  50   0   0\n",
      "1   0   3  47\n",
      "2   0  28  22\n",
      "k-means\n",
      "        acc       mse  r squared       sil        di      dbi      dbcv\n",
      "0  0.893333  0.106667       0.84  0.553454  0.098807  4.31806  0.479025\n",
      "confusion matrixes:\n",
      "    0   1   2\n",
      "0  50   0   0\n",
      "1   0  48   2\n",
      "2   0  14  36\n"
     ]
    }
   ],
   "source": [
    "# test \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "k = 3\n",
    "\n",
    "_, cluster_centers, labels = maximin_clustering(X, threshold=k)\n",
    "print('maxmin')\n",
    "\n",
    "metrics = []\n",
    "metrics.append(classifiaction_metrics(labels, y, twoClasses=False) + cluster_metrics(X, labels, cluster_centers))\n",
    "df = pd.DataFrame(data=metrics, columns=['acc', 'mse', 'r squared', 'con', 'sil', 'di', 'dbi', 'dbcv'])\n",
    "\n",
    "\n",
    "print(df.drop(['con'], axis=1))\n",
    "print('confusion matrixes:')\n",
    "for sample in metrics:\n",
    "    print(sample[3])\n",
    "\n",
    "labels, centers = k_means(X, k)\n",
    "print('k-means')\n",
    "\n",
    "metrics = []\n",
    "metrics.append(classifiaction_metrics(labels, y, twoClasses=False) + cluster_metrics(X, labels, centers))\n",
    "df = pd.DataFrame(data=metrics, columns=['acc', 'mse', 'r squared', 'con', 'sil', 'di', 'dbi', 'dbcv'])\n",
    "\n",
    "\n",
    "print(df.drop(['con'], axis=1))\n",
    "print('confusion matrixes:')\n",
    "for sample in metrics:\n",
    "    print(sample[3])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
